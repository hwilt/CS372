{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e57e553",
   "metadata": {},
   "source": [
    "# Classifying <a href = \"https://magenta.tensorflow.org/datasets/nsynth\">NSynth Instruments</a> with Fully Connected Feedforward Neural Nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0e30ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy import signal\n",
    "import librosa\n",
    "\n",
    "# Download data to your colab instance\n",
    "#!wget https://raw.githubusercontent.com/ursinus-cs372-s2023/Week13_NSynthClassify/main/data/nsynth_valid.mp3\n",
    "#!wget https://raw.githubusercontent.com/ursinus-cs372-s2023/Week13_NSynthClassify/main/data/nsynth_test.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df0fb9",
   "metadata": {},
   "source": [
    "# Torch Data Loader for NSynth Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92072e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['bass_electronic', 'bass_synthetic', 'brass_acoustic', 'flute_acoustic', 'flute_synthetic', 'guitar_acoustic', 'guitar_electronic', 'keyboard_acoustic', 'keyboard_electronic', 'keyboard_synthetic', 'mallet_acoustic', 'organ_electronic', 'reed_acoustic', 'string_acoustic', 'vocal_acoustic', 'vocal_synthetic']\n",
    "\n",
    "class Synth(Dataset):\n",
    "    def __init__(self, audio_filename, labels_filename, sr=8000, sample_len=4):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        audio_filename: string\n",
    "            Path to audio file\n",
    "        labels_filename: string\n",
    "            Path to labels file\n",
    "        sr: int\n",
    "            Audio sample rate to use\n",
    "        sample_len: int\n",
    "            Length of each sample, in seconds\n",
    "        \"\"\"\n",
    "        self.x, self.sr = librosa.load(audio_filename, sr=sr)\n",
    "        self.labels = np.loadtxt(labels_filename)\n",
    "        print(\"Finished loading audio \", audio_filename)\n",
    "        self.sample_len = sample_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return a tuple (x, y)\n",
    "        \"\"\"\n",
    "        ## TODO: Fill this in\n",
    "        ## Return the idxth clip and a 1-hot vector representing its class\n",
    "        L = self.sr*self.sample_len\n",
    "        x = self.x[idx*L:(idx+1)*L]\n",
    "        label = int(self.labels[idx])\n",
    "        y = np.zeros(len(LABELS))\n",
    "        y[label] = 1\n",
    "        x = librosa.feature.mfcc(y=x, sr=self.sr).flatten()\n",
    "        x = torch.from_numpy(np.array(x, dtype=np.float32))\n",
    "        y = torch.from_numpy(np.array(y, dtype=np.float32))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba640911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading audio  data/nsynth_valid.mp3\n",
      "Finished loading audio  data/nsynth_test.mp3\n"
     ]
    }
   ],
   "source": [
    "sr = 8000\n",
    "sample_len = 4\n",
    "data_train = Synth(\"data/nsynth_valid.mp3\", \"labels_valid.txt\", sr, sample_len)\n",
    "data_test = Synth(\"data/nsynth_test.mp3\", \"labels_test.txt\", sr, sample_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673b87f",
   "metadata": {},
   "source": [
    "## PyTorch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, outputs):\n",
    "    from scipy import sparse\n",
    "    x1 = torch.argmax(labels, axis=1).detach().cpu()\n",
    "    x2 = torch.argmax(outputs, axis=1).detach().cpu()\n",
    "    I = np.array(x1.numpy(), dtype=int)\n",
    "    J = np.array(x2.numpy(), dtype=int)\n",
    "    K = len(LABELS)\n",
    "    D = sparse.coo_matrix((np.ones(I.size), (I, J)), shape=(K, K))\n",
    "    plt.imshow(D.toarray())\n",
    "    plt.xticks(np.arange(K), LABELS, rotation='vertical')\n",
    "    plt.yticks(np.arange(K), LABELS)\n",
    "    plt.ylabel(\"Ground Truth Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    correct = 100*np.sum(np.diag(D))/np.sum(D)\n",
    "    plt.title(\"{:.3f}% Correct\".format(correct))\n",
    "    return np.sum(np.diag(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffe0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use the GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"Device: \", device)\n",
    "\n",
    "## Step 2: Create sequential neural net model (setup a function space)\n",
    "\n",
    "## TODO: Create your model\n",
    "model = nn.Sequential() ## TODO: More stuff here\n",
    "\n",
    "# Output of layer 3 will go through a logistic function\n",
    "\n",
    "## Step 3: Setup the loss function\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 10 # Each \"epoch\" is a loop through the entire dataset\n",
    "# and we use this to update the parameters\n",
    "losses = []\n",
    "accuracy = []\n",
    "for epoch in range(n_epochs):\n",
    "    print(\".\", end=\"\")\n",
    "    loader = DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "    for X, Y in loader: # Go through each mini batch\n",
    "        # Move inputs/outputs to GPU\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        # Reset the optimizer's gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Run the sequential model on all inputs\n",
    "        Y_est = model(X)\n",
    "        # Compute the loss function comparing Y_est to Y\n",
    "        loss = loss_fn(Y_est, Y)\n",
    "        # Compute the gradients of the loss function with respect\n",
    "        # to all of the parameters of the model\n",
    "        loss.backward()\n",
    "        # Update the parameters based on the gradient and\n",
    "        # the optimization scheme\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Look at results on test set\n",
    "    test_loader = DataLoader(data_test, batch_size=len(data_test))\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    total_loss = loss_fn(outputs, labels)\n",
    "    losses.append(total_loss.item())\n",
    "    plt.figure()\n",
    "    num_correct = plot_confusion_matrix(labels, outputs)\n",
    "    accuracy.append(num_correct/len(test_data))\n",
    "    print(\"Epoch {}, accuracy {:.3f}\".format(epoch, accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcedbb",
   "metadata": {},
   "source": [
    "## Plot Optimization Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc22423",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(losses)\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.subplot(212)\n",
    "plt.plot(np.array(accuracy)*100)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4b224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
